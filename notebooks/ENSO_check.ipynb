{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMYLE: Nino3.4 Check \n",
    " - Check that Nino3.4 prediction looks reasonable at early lead times\n",
    " - data I/O functions based on template from daniel kennedy (djk2120@ucar.edu): https://github.com/djk2120/cesm-lens\n",
    " - Optimized for dask, Elizabeth Maroon, 3/26/2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr \n",
    "import numpy as np  \n",
    "import cftime\n",
    "import copy\n",
    "import scipy.stats\n",
    "from scipy import signal\n",
    "import cartopy.crs as ccrs\n",
    "import glob\n",
    "import dask\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dask Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close out Dask Cluster and release workers:\n",
    "# NOTE:  only run this cell to terminate Dask Cluster!\n",
    "#cluster.close()\n",
    "#client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY RUN THIS CELL ONCE  \n",
    "# NOTE: you may need to change the project number\n",
    "proj = 'NCGD0011'\n",
    "ncores = 36\n",
    "nmem   = str(int(375*ncores/36))+'GB'\n",
    "from ncar_jobqueue import NCARCluster \n",
    "from dask.distributed import Client\n",
    "cluster = NCARCluster(cores=ncores,\n",
    "                     death_timout=60, \n",
    "                     processes=ncores, memory=nmem,\n",
    "                     project=proj,\n",
    "                     walltime='3:00:00')\n",
    "cluster.scale(ncores)\n",
    "\n",
    "#cluster=NCARCluster(memory='50GB')\n",
    "#cluster.adapt(minimum=4,maximum=18,wait_count=30) #Liz's preferred setup - scales up/down on the fly\n",
    "\n",
    "client = Client(cluster)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster\n",
    "#client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data I/O functions:\n",
    " - Run each of these cells, then proceed to Main Processing\n",
    " - Note that these functions are currently hard-wired to retrieve ocean monthly data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_dict(topdir,field,mem,stmon):\n",
    "    ''' returns a dictionary of filepaths keyed by initialization year, \n",
    "    for a given field, ensemble member, and initialization month '''\n",
    "    memstr = '{0:03d}'.format(mem)\n",
    "    monstr = '{0:02d}'.format(stmon)\n",
    "    filepaths = {}\n",
    "    \n",
    "    #build casename\n",
    "    casebase = 'b.e21.BSMYLE.f09_g17.'\n",
    "    ocn_monthly = 'ocn/proc/tseries/month_1/'\n",
    "    casename = casebase+'????-'+monstr+'.'+memstr\n",
    "    filetemp = topdir+casename+'/'+ocn_monthly+casename+'.pop.h.'+field+'.*.nc'\n",
    "    #find all the relevant files\n",
    "    files = glob.glob(filetemp)\n",
    "        \n",
    "    for file in files:\n",
    "        #isolate initialization year from the file name\n",
    "        ystr = file.split(casebase)[-1]\n",
    "        y0 = int(ystr[0:4])\n",
    "        filepaths[y0]=file\n",
    "        \n",
    "    return filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test how it works:\n",
    "filepaths = file_dict('/glade/campaign/cesm/development/espwg/SMYLE/archive/','SSH',1,11)\n",
    "filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_file_list_by_member(datadir,ens,field,firstyear,lastyear,stmon):\n",
    "    ''' retrieve a list of files containing the given ensemble'''\n",
    "    ens = np.array(ens)+1\n",
    "    yrs = np.arange(firstyear,lastyear+1)\n",
    "    files = []    # a list of lists, dim0=ens, dim1=time\n",
    "    ix = np.zeros(ens.shape)+1\n",
    "    \n",
    "    for ee,i in zip(ens,range(len(ens))):\n",
    "        ffs = []  # a list of files for this ee\n",
    "        file0 = ''\n",
    "        first = True\n",
    "        for yr in yrs:\n",
    "            #fetch filepaths\n",
    "            if first:\n",
    "                filepaths = file_dict(datadir,field,ee,stmon)\n",
    "                first     = False  \n",
    "            #append file if it is new\n",
    "            if yr in filepaths.keys():\n",
    "                file = filepaths[yr]\n",
    "                if file != file0:\n",
    "                    ffs.append(file)\n",
    "                    file0 = file\n",
    "        \n",
    "        #append this ensemble member to files\n",
    "        if ffs:  #only append if you found files\n",
    "            files.append(ffs)\n",
    "        else:\n",
    "            ix[i] = 0\n",
    "    return files,ens[ix==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test how it works\n",
    "#files,ens = nested_file_list_by_member('/glade/campaign/cesm/development/espwg/SMYLE/archive/',range(10),'SSH',1958,1997,11)\n",
    "#files[0]\n",
    "#ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_file_list_by_year(datadir,ens,field,firstyear,lastyear,stmon):\n",
    "    ''' retrieve a nested list of files for these start years and ensemble members'''\n",
    "    ens = np.array(ens)+1\n",
    "    yrs = np.arange(firstyear,lastyear+1)\n",
    "    files = []    # a list of lists, dim0=start_year, dim1=ens\n",
    "    ix = np.zeros(yrs.shape)+1\n",
    "    \n",
    "    for yy,i in zip(yrs,range(len(yrs))):\n",
    "        ffs = []  # a list of files for this yy\n",
    "        file0 = ''\n",
    "        first = True\n",
    "        for ee in ens:\n",
    "            filepaths = file_dict(datadir,field,ee,stmon)\n",
    "            #append file if it is new\n",
    "            if yy in filepaths.keys():\n",
    "                file = filepaths[yy]\n",
    "                if file != file0:\n",
    "                    ffs.append(file)\n",
    "                    file0 = file\n",
    "        \n",
    "        #append this ensemble member to files\n",
    "        if ffs:  #only append if you found files\n",
    "            files.append(ffs)\n",
    "        else:\n",
    "            ix[i] = 0\n",
    "    return files,yrs[ix==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test how it works\n",
    "files,yrs = nested_file_list_by_year('/glade/campaign/cesm/development/espwg/SMYLE/archive/',range(10),'SSH',1958,1997,11)\n",
    "files[0]\n",
    "yrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_monthly_data(datadir,ens,field,firstyear,lastyear,stmon):\n",
    "    ''' returns an xarray dataset containing the requested ensemble\n",
    "    ens   = list of members, via simple sequential key e.g. range(50) gets the first 50 members\n",
    "            [0,2,4] would get the first, third, and fifth ensemble members (see get_members)\n",
    "    firstyear = int [1850-1950]\n",
    "    lastyear  = int [1850-1950] '''\n",
    "\n",
    "    ds = xr.Dataset()    #instantiate Dataset\n",
    "    lm = np.arange(1,25) # hard-wired for 24-month leads\n",
    "    files,yrs = nested_file_list_by_year(datadir,ens,field,firstyear,lastyear,stmon)\n",
    "    ens = np.array(range(10))+1\n",
    "#    ensdim  = xr.DataArray(ens, dims='M', name='member')\n",
    "#    yeardim = xr.DataArray(yrs, dims='Y', name='startyear')\n",
    "#    leaddim = xr.DataArray(lm, dims='LM', name='leadmonth')\n",
    "#    dims    = [yeardim,ensdim,leaddim,None,None]\n",
    "    \n",
    "    # all members should have the same number of files, otherwise abort\n",
    "    nfs = np.array([len(ffs) for ffs in files])\n",
    "    print(nfs)\n",
    "    print(nfs[0])\n",
    "    print(len(nfs))\n",
    "    if np.sum(nfs==nfs[0])==len(nfs):\n",
    "        complete_set=True   # same number of files\n",
    "    else:\n",
    "        raise ValueError('ERROR: Incomplete set of files')\n",
    "        \n",
    "    if complete_set: #read all data in one go\n",
    "        dsets = []\n",
    "        #This for loop is leading to inefficiencies. Forces everything to be read in series.\n",
    "        #Cannot be parallelized as is. As a result, the work on all cores is split over all cores\n",
    "        #but for one hindcast there isn't enough work for all the cores -> inefficient\n",
    "        #replacing with a function and a map_blocks\n",
    "        #for ffs in files:\n",
    "        #    d0 = xr.open_mfdataset(ffs,combine='nested',parallel=True,concat_dim='M',data_vars=[field],chunks={})\n",
    "        #    # quick fix to adjust time vector for monthly data  \n",
    "        #    nmonths = len(d0.time)\n",
    "        #    yr0 = d0['time.year'][0].values\n",
    "        #    d0['time'] =xr.cftime_range(str(yr0),periods=nmonths,freq='MS')\n",
    "        #    d0 = d0.assign_coords(M=(\"M\",ens))\n",
    "        #    d0 = d0.assign_coords(L=(\"time\",lm))\n",
    "        #    d0 = d0.swap_dims({'time': 'L'})\n",
    "        #    d0 = d0.reset_coords([\"time\"])\n",
    "        #    dsets.append(d0)\n",
    "        in_obj = [[ffs, field, ens, lm] for ffs in files]\n",
    "        dsets = client.map(open_onehindcast, in_obj)\n",
    "        \n",
    "        dsets = client.gather(dsets)\n",
    "\n",
    "        tmp = xr.concat(dsets,dim='Y',data_vars=[field,'time','time_bound'], coords='minimal', compat='override')\n",
    "        #potentially dangerous compat/coords option - xarray is NOT checking that the coordinates \n",
    "        #are the same across all files - pulling values of shared coords from the first file only\n",
    "        #speeds up read-in time by ~1/3\n",
    "        tmp = tmp.assign_coords(Y=(\"Y\",yrs))\n",
    "    ds[field] = tmp[field]\n",
    "    ds['time'] = tmp['time']\n",
    "    ds['time_bound'] = tmp['time_bound']\n",
    "    ds['TAREA'] = tmp['TAREA']\n",
    "    ds['UAREA'] = tmp['UAREA']\n",
    "\n",
    "    #grab one copy of the various extra variables, e.g. landfrac,area\n",
    "#    tmp = xr.open_dataset(files[0][0])\n",
    "#    for thisvar in tmp.data_vars:\n",
    "#        if 'time' not in tmp[thisvar].coords:\n",
    "#            ds[thisvar]=tmp[thisvar]\n",
    "\n",
    "    # quick fix to adjust time vector for monthly data        \n",
    "#    nmonths = len(ds.time)\n",
    "#    yr0 = ds['time.year'][0].values\n",
    "#    ds['time'] =xr.cftime_range(str(yr0),periods=nmonths,freq='MS')\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_onehindcast(in_obj):\n",
    "    ffs = in_obj[0]  #unwrap the list\n",
    "    field = in_obj[1]\n",
    "    ens = in_obj[2]\n",
    "    lm = in_obj[3]\n",
    "    \n",
    "    d0 = xr.open_mfdataset(ffs,combine='nested',parallel=True,concat_dim='M',data_vars=[field],chunks={},compat='override', coords='minimal')\n",
    "    #added compat=override, coords=minimal here. Assumes that all hindcasts have same dims/coords. Seems a little dangerous\n",
    "    #but REALLY speeds things up. And we know that the coords are the same for all of SMYLE anyway.\n",
    "\n",
    "    # quick fix to adjust time vector for monthly data  \n",
    "    nmonths = len(d0.time)\n",
    "    yr0 = d0['time.year'][0].values\n",
    "    d0['time'] =xr.cftime_range(str(yr0),periods=nmonths,freq='MS')\n",
    "    d0 = d0.assign_coords(M=(\"M\",ens))\n",
    "    d0 = d0.assign_coords(L=(\"time\",lm))\n",
    "    d0 = d0.swap_dims({'time': 'L'})\n",
    "    d0 = d0.reset_coords([\"time\"])\n",
    "    \n",
    "    return d0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in POP monthly field\n",
    "- Chosen field is returned as a dask array with leading dimensions of Y (initialization year), M (ensemble member), and L (lead month)\n",
    "- \"time\" and \"time_bound\" variables, which give prediction verification time, are also dimensioned with (Y,L) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "datadir = '/glade/campaign/cesm/development/espwg/SMYLE/archive/'\n",
    "ens = range(10)\n",
    "firstyear = 1971 #1958 #earlier hindcasts got moved?\n",
    "lastyear  = 1997\n",
    "ds_temp = get_monthly_data(datadir,ens,'TEMP',firstyear,lastyear,11)\n",
    "ds_temp.nbytes/1e9 #GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine Nino3.4 SST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute masks & weights for Nino3.4 regional average\n",
    "tlat = ds_temp.TLAT\n",
    "tlon = xr.where(ds_temp.TLONG>180.,ds_temp.TLONG-360.,ds_temp.TLONG)\n",
    "\n",
    "# Nino3.4\n",
    "y0a = -5.\n",
    "y1a =  5.\n",
    "x0a = -170.\n",
    "x1a = -120.\n",
    "region1 = (tlat>=y0a) & (tlat<=y1a) & (tlon>=x0a) & (tlon<=x1a)\n",
    "areawgt1 = xr.where(region1, ds_temp.TAREA.fillna(0),0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here, perform actual computation, returning xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smyle_nino34 = ds_temp.TEMP.isel(z_t=0).weighted(areawgt1).mean((\"nlon\", \"nlat\")).load()\n",
    "time_bound = ds_temp.time_bound.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get NOAA ERSSTv5 Nino3.4 Obs\n",
    "ds_obs = xr.open_dataset('/glade/p/cgd/oce/people/yeager/obs/SST/NOAA_ERSSTv5/ersst.v5.188001-201712.gx1v6.nc',decode_times=False)\n",
    "obs_time_vals = [cftime.DatetimeNoLeap(1880+year, 1+month, 15) for year in range(138) for month in range(12)]\n",
    "ds_obs['time'] = obs_time_vals\n",
    "obs_nino34 = ds_obs.sst.weighted(areawgt1).mean((\"nlon\", \"nlat\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Plot\n",
    "- For some reason, I can't get `errorbar` or `scatter` plot methods to handle the cftime.DatetimeNoLeap time values. `plot` can handle it. \n",
    "The error message reports it needs cftime.datetime objects, but isinstance(smyletime.values[0],cftime.datetime) returns True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure\n",
    "fig, ((ax1, ax2)) = plt.subplots(nrows=2, ncols=1, figsize=(15, 10))\n",
    "\n",
    "#tmon = np.linspace(1958. + 0.5*(1./12), 2019 - 0.5*(1./12), num=61*12)\n",
    "xticks = [1960,1965,1975,1985,1995,2005,2015]\n",
    "xmin = cftime.num2date(0, 'days since 1955-01-01 00:00:00', calendar='noleap')\n",
    "xmax = cftime.num2date(0, 'days since 2020-01-01 00:00:00', calendar='noleap')\n",
    "\n",
    "ax1.set_ylabel(r'$^{\\circ}$C')\n",
    "ax1.set_ylim(23,30)\n",
    "ax1.set_xlim(xmin,xmax)\n",
    "#ax1.set_xticks(xticks)\n",
    "lm = 1\n",
    "smyletime = time_bound.isel(L=lm).mean('d2')\n",
    "ax1.set_title('Nino3.4 SST, Lead Month = {}'.format(lm), fontdict={'size':16})\n",
    "ax1.plot(obs_nino34.time, obs_nino34,linewidth=2,color='k',label='OBS')\n",
    "#smyle_range = [smyle_nino34.sel(L=lm).min('M'),smyle_nino34.sel(L=lm).max('M')]\n",
    "#ax1.errorbar(smyletime,smyle_nino34.sel(L=lm).mean('M'),yerr=smyle_range,fmt='o',color='b',label='SMYLE')\n",
    "ax1.plot(smyletime,smyle_nino34.sel(L=lm).mean('M'),'o',color='b',label='SMYLE')\n",
    "ax1.grid()\n",
    "ax1.legend(loc='lower right')\n",
    "\n",
    "ax2.set_ylabel(r'$^{\\circ}$C')\n",
    "ax2.set_ylim(23,30)\n",
    "ax2.set_xlim(xmin,xmax)\n",
    "#ax1.set_xticks(xticks)\n",
    "lm = 2\n",
    "smyletime = time_bound.isel(L=lm).mean('d2')\n",
    "ax2.set_title('Nino3.4 SST, Lead Month = {}'.format(lm), fontdict={'size':16})\n",
    "ax2.plot(obs_nino34.time, obs_nino34,linewidth=2,color='k',label='OBS')\n",
    "#smyle_range = [smyle_nino34.sel(L=lm).min('M'),smyle_nino34.sel(L=lm).max('M')]\n",
    "#ax2.errorbar(smyletime,smyle_nino34.sel(L=lm).mean('M'),yerr=smyle_range,fmt='o',color='b',label='SMYLE')\n",
    "ax2.plot(smyletime,smyle_nino34.sel(L=lm).mean('M'),'o',color='b',label='SMYLE')\n",
    "ax2.grid()\n",
    "ax2.legend(loc='lower right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapcdi-analysis",
   "language": "python",
   "name": "rapcdi-analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
